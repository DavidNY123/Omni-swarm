{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "WARNING:tensorflow:From <ipython-input-1-e4d373104107>:43: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Load 5735 images\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "tensorflow.keras.backend.set_learning_phase(0)\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.image import resampler\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tfa.image.resampler\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import numpy as np\n",
    "model_dir = \"./config/hfnet_v2\"\n",
    "output_saved_model_dir = \"./config/hfnet_v2_trt\" \n",
    "output_saved_model_dir_netvlad = \"./config/hfnet_v2_netvlad_trt\" \n",
    "output_frozen_path = \"./config/hf_frozen_208x400_v2.pb\"\n",
    "output_frozen_path_sp = \"./config/hf_frozen_208x400_v2_superpoint.pb\"\n",
    "output_frozen_path_netvlad = \"./config/hf_frozen_208x400_netvlad.pb\"\n",
    "verify_images_path= \"/ssd/drone_data_process/images\"\n",
    "\n",
    "\n",
    "img = cv2.imread(\"./db1.jpg\")\n",
    "img = cv2.resize(img, (400, 400))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = img[0:208, 0:400]\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "tfa.register.register_all()\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (400, 208))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "images = load_images_from_folder(verify_images_path)\n",
    "print(f\"Load {len(images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./config/hfnet_v2/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Net at 0x7f986586a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(object):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.model_filepath = model_path\n",
    "        self.load_graph(model_filepath=self.model_filepath)\n",
    "\n",
    "\n",
    "    def load_graph(self, model_filepath):\n",
    "        print(\"Loading model...\")\n",
    "\n",
    "\n",
    "        with tf.io.gfile.GFile(model_filepath, 'rb') as f:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            with tf.Graph().as_default() as graph:\n",
    "                tf.import_graph_def(graph_def, name='')\n",
    "                signature = tf.compat.v1.saved_model.signature_def_utils.predict_signature_def(\n",
    "                    inputs={\n",
    "                        'image':graph.get_tensor_by_name('image:0'),\n",
    "                        'k':graph.get_tensor_by_name('k:0'),\n",
    "                        'radius':graph.get_tensor_by_name('radius:0')\n",
    "                           },\n",
    "                    outputs={'global_descriptor': graph.get_tensor_by_name('global_descriptor:0'),\n",
    "                        'keypoints': graph.get_tensor_by_name('keypoints:0'),\n",
    "                        'local_descriptors': graph.get_tensor_by_name('local_descriptors:0')}\n",
    "                )\n",
    "                builder = tf.compat.v1.saved_model.Builder(\"./config/hfnet_v2/\")\n",
    "                builder.add_meta_graph_and_variables(\n",
    "                    sess=sess,\n",
    "                    tags=[tf.compat.v1.saved_model.tag_constants.SERVING],\n",
    "                    signature_def_map={'serving_default': signature}\n",
    "                )\n",
    "                builder.save()\n",
    "class NetVLAD(object):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.model_filepath = model_path\n",
    "        self.load_graph(model_filepath=self.model_filepath)\n",
    "\n",
    "\n",
    "    def load_graph(self, model_filepath):\n",
    "        print(\"Loading model...\")\n",
    "\n",
    "\n",
    "        with tf.io.gfile.GFile(model_filepath, 'rb') as f:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            with tf.Graph().as_default() as graph:\n",
    "                tf.import_graph_def(graph_def, name='')\n",
    "                signature = tf.compat.v1.saved_model.signature_def_utils.predict_signature_def(\n",
    "                    inputs={\n",
    "                        'image':graph.get_tensor_by_name('image:0'),\n",
    "                           },\n",
    "                    outputs={'global_descriptor': graph.get_tensor_by_name('global_descriptor:0')}\n",
    "                )\n",
    "                builder = tf.compat.v1.saved_model.Builder(\"./config/hfnet_v2_netvlad/\")\n",
    "                builder.add_meta_graph_and_variables(\n",
    "                    sess=sess,\n",
    "                    tags=[tf.compat.v1.saved_model.tag_constants.SERVING],\n",
    "                    signature_def_map={'serving_default': signature}\n",
    "                )\n",
    "                builder.save()\n",
    "                \n",
    "class NetSuperPoint(object):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.model_filepath = model_path\n",
    "        self.load_graph(model_filepath=self.model_filepath)\n",
    "\n",
    "\n",
    "    def load_graph(self, model_filepath):\n",
    "        print(\"Loading model...\")\n",
    "\n",
    "\n",
    "        with tf.io.gfile.GFile(model_filepath, 'rb') as f:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            with tf.Graph().as_default() as graph:\n",
    "                tf.import_graph_def(graph_def, name='')\n",
    "                signature = tf.compat.v1.saved_model.signature_def_utils.predict_signature_def(\n",
    "                    inputs={\n",
    "                        'image':graph.get_tensor_by_name('image:0'),\n",
    "                        'k':graph.get_tensor_by_name('k:0'),\n",
    "                        'radius':graph.get_tensor_by_name('radius:0')\n",
    "                           },\n",
    "                    outputs={'keypoints': graph.get_tensor_by_name('keypoints:0'),\n",
    "                        'local_descriptors': graph.get_tensor_by_name('local_descriptors:0')}\n",
    "                )\n",
    "                builder = tf.compat.v1.saved_model.Builder(\"./config/hfnet_v2_superpoint/\")\n",
    "                builder.add_meta_graph_and_variables(\n",
    "                    sess=sess,\n",
    "                    tags=[tf.compat.v1.saved_model.tag_constants.SERVING],\n",
    "                    signature_def_map={'serving_default': signature}\n",
    "                )\n",
    "                builder.save()\n",
    "\n",
    "\n",
    "Net(output_frozen_path)\n",
    "#NetVLAD(output_frozen_path_netvlad)\n",
    "#NetSuperPoint(output_frozen_path_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "conversion_params = conversion_params._replace(\n",
    "    max_workspace_size_bytes=(1<<30))\n",
    "conversion_params = conversion_params._replace(precision_mode=\"FP16\")\n",
    "conversion_params = conversion_params._replace(\n",
    "    maximum_cached_engines=100)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=\"./config/hfnet_v2_superpoint\",\n",
    "    conversion_params=conversion_params)\n",
    "converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shuffle()\n",
    "def my_input_fn():\n",
    "    for i in range(100):\n",
    "        img = images[i]\n",
    "        _img = np.expand_dims(img, axis=2)\n",
    "        _img = np.array([_img]).astype(np.float32)\n",
    "        #print(_img.shape)\n",
    "    yield _img, 200, 4\n",
    "converter.build(input_fn=my_input_fn)\n",
    "converter.save(\"./config/hfnet_v2_superpoint_trt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
