{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "WARNING:tensorflow:From <ipython-input-2-9d76b98d0f9a>:40: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Load 5735 images\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "tensorflow.keras.backend.set_learning_phase(0)\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.image import resampler\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tfa.image.resampler\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import numpy as np\n",
    "model_dir = \"./config/hfnet_v2\"\n",
    "output_saved_model_dir = \"./config/hfnet_v2_trt\" \n",
    "output_frozen_path = \"./config/hf_frozen_208x400_v2.pb\"\n",
    "verify_images_path= \"/ssd/drone_data_process/images\"\n",
    "\n",
    "\n",
    "img = cv2.imread(\"./db1.jpg\")\n",
    "img = cv2.resize(img, (400, 400))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = img[0:208, 0:400]\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "tfa.register.register_all()\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (400, 208))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "images = load_images_from_folder(verify_images_path)\n",
    "print(f\"Load {len(images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(object):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.model_filepath = model_path\n",
    "        self.load_graph(model_filepath=self.model_filepath)\n",
    "\n",
    "\n",
    "    def load_graph(self, model_filepath):\n",
    "        print(\"Loading model...\")\n",
    "\n",
    "\n",
    "        with tf.io.gfile.GFile(model_filepath, 'rb') as f:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            with tf.Graph().as_default() as graph:\n",
    "                tf.import_graph_def(graph_def, name='')\n",
    "                signature = tf.compat.v1.saved_model.signature_def_utils.predict_signature_def(\n",
    "                    inputs={'image':graph.get_tensor_by_name('image:0')},\n",
    "                    outputs={'global_descriptor': graph.get_tensor_by_name('global_descriptor:0'),\n",
    "                        'keypoints': graph.get_tensor_by_name('keypoints:0'),\n",
    "                        'local_descriptors': graph.get_tensor_by_name('local_descriptors:0')}\n",
    "                )\n",
    "                builder = tf.compat.v1.saved_model.Builder(\"./config/hfnet_v2/\")\n",
    "                builder.add_meta_graph_and_variables(\n",
    "                    sess=sess,\n",
    "                    tags=[tf.compat.v1.saved_model.tag_constants.SERVING],\n",
    "                    signature_def_map={'serving_default': signature}\n",
    "                )\n",
    "                builder.save()\n",
    "\n",
    "\n",
    "Net(output_frozen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 0)\n",
      "ERROR:tensorflow:Loaded TensorRT 7.1.0 but linked TensorFlow against TensorRT 7.1.3. TensorRT does not support forward compatibility. It is also required to use the same major version of TensorRT during compilation and runtime.\n",
      "INFO:tensorflow:Loaded TensorRT 7.1.0 and linked TensorFlow against TensorRT 7.1.3. This is supported because TensorRT  minor/patch upgrades are backward compatible\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./config/hfnet_v2_trt/assets\n"
     ]
    }
   ],
   "source": [
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "conversion_params = conversion_params._replace(\n",
    "    max_workspace_size_bytes=(1<<30))\n",
    "conversion_params = conversion_params._replace(precision_mode=\"FP16\")\n",
    "conversion_params = conversion_params._replace(\n",
    "    maximum_cached_engines=100)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=model_dir,\n",
    "    conversion_params=conversion_params)\n",
    "converter.convert()\n",
    "# np.shuffle()\n",
    "def my_input_fn():\n",
    "    for i in range(100):\n",
    "        img = images[i]\n",
    "        _img = np.expand_dims(img, axis=2)\n",
    "        _img = np.array([[_img]]).astype(np.float32)\n",
    "        #print(_img.shape)\n",
    "    yield _img\n",
    "converter.build(input_fn=my_input_fn)\n",
    "converter.save(output_saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Graph 14.497892618179321 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "saved_model_loaded = tf.saved_model.load(\n",
    "    output_saved_model_dir, tags=[tag_constants.SERVING])\n",
    "# saved_model_loaded = tf.saved_model.load(\n",
    "#     output_saved_model_dir)\n",
    "\n",
    "frozen_func = graph_func = saved_model_loaded.signatures[\n",
    "   signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "\n",
    "#frozen_func = convert_to_constants.convert_variables_to_constants_v2(\n",
    "#    graph_func)\n",
    "print(\"--- Loading Graph %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Try\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  Input to reshape is a tensor with 332800 values, but the requested shape has 7680\n\t [[{{node PartitionedCall/pred/global_head/vlad/Reshape}}]]\n\t [[PartitionedCall/pred/descriptor_sampling/mul/_22]]\n  (1) Invalid argument:  Input to reshape is a tensor with 332800 values, but the requested shape has 7680\n\t [[{{node PartitionedCall/pred/global_head/vlad/Reshape}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_signature_wrapper_1110]\n\nFunction call stack:\nsignature_wrapper -> signature_wrapper\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4a766fe6ce9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First Try\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- First trial %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4a766fe6ce9c>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(_img.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozen_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m     99\u001b[0m           map(get_cross_replica_handle, captured_inputs))\n\u001b[1;32m    100\u001b[0m     return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\n\u001b[0;32m--> 101\u001b[0;31m                                                     cancellation_manager)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  Input to reshape is a tensor with 332800 values, but the requested shape has 7680\n\t [[{{node PartitionedCall/pred/global_head/vlad/Reshape}}]]\n\t [[PartitionedCall/pred/descriptor_sampling/mul/_22]]\n  (1) Invalid argument:  Input to reshape is a tensor with 332800 values, but the requested shape has 7680\n\t [[{{node PartitionedCall/pred/global_head/vlad/Reshape}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_signature_wrapper_1110]\n\nFunction call stack:\nsignature_wrapper -> signature_wrapper\n"
     ]
    }
   ],
   "source": [
    "def run(img):\n",
    "    _img = np.expand_dims(img, axis=2)\n",
    "    _img = np.array([_img]).astype(np.float)\n",
    "    _img = tf.convert_to_tensor(_img, dtype=tf.float32)\n",
    "    #print(_img.shape)\n",
    "    output = frozen_func(_img)\n",
    "    return output\n",
    "\n",
    "img = cv2.imread(\"./db1.jpg\")\n",
    "img = cv2.resize(img, (400, 400))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = img[0:208, 0:400]\n",
    "print(\"First Try\")\n",
    "start_time = time.time()\n",
    "ret = run(img)\n",
    "print(\"--- First trial %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "def draw(img, ret):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    kps = ret[\"keypoints\"][0].numpy()\n",
    "    for kp in kps:\n",
    "        img = cv2.circle(img, (kp[0], kp[1]), 3, (255, 255, 255))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    _time = time.time()\n",
    "    ret = run(images[i])\n",
    "    if (time.time() - _time > 0.01):\n",
    "        print(f\"Img {i} cost {(time.time() - _time)*1000}ms\")\n",
    "        draw(images[i], ret)\n",
    "        \n",
    "print(f\"--- Try {len(images)} images, average {(time.time() - start_time)/len(images)*1000} ms ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 400)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
